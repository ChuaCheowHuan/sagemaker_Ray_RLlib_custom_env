{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "mod_op_sp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WRO_it6g4yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/bin/bash ./setup.sh\n",
        "\n",
        "from time import gmtime, strftime\n",
        "import sagemaker \n",
        "role = sagemaker.get_execution_role()\n",
        "\n",
        "sage_session = sagemaker.session.Session()\n",
        "s3_bucket = sage_session.default_bucket()  \n",
        "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
        "print(\"S3 bucket path: {}\".format(s3_output_path))\n",
        "\n",
        "job_name_prefix = 'ArrivalSim'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0C9uR4_g4yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pygmentize ./src/mod_op_env.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuMWgqhRg4ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pygmentize ./src/mod_op_train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHQx5HWHg4yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
        "\n",
        "estimator = RLEstimator(entry_point=\"mod_op_train.py\", # Our launcher code\n",
        "                        source_dir='src', # Directory where the supporting files are at. All of this will be\n",
        "                                          # copied into the container.\n",
        "                        dependencies=[\"common/sagemaker_rl\"], # some other utils files.\n",
        "                        toolkit=RLToolkit.RAY, # We want to run using the Ray toolkit against the ray container image.\n",
        "                        framework=RLFramework.TENSORFLOW, # The code is in tensorflow backend.\n",
        "                        toolkit_version='0.5.3', # Toolkit version. This will also choose an apporpriate tf version.                                               \n",
        "                        #toolkit_version='0.6.5', # Toolkit version. This will also choose an apporpriate tf version.                        \n",
        "                        role=role, # The IAM role that we created at the begining.\n",
        "                        #train_instance_type=\"ml.m4.xlarge\", # Since we want to run fast, lets run on GPUs.\n",
        "                        train_instance_type=\"local\", # Since we want to run fast, lets run on GPUs.\n",
        "                        train_instance_count=1, # Single instance will also work, but running distributed makes things \n",
        "                                                # fast, particularly in the case of multiple rollout training.\n",
        "                        output_path=s3_output_path, # The path where we can expect our trained model.\n",
        "                        base_job_name=job_name_prefix, # This is the name we setup above to be to track our job.\n",
        "                        hyperparameters = {      # Some hyperparameters for Ray toolkit to operate.\n",
        "                          \"s3_bucket\": s3_bucket,\n",
        "                          \"rl.training.stop.training_iteration\": 2, # Number of iterations.\n",
        "                          \"rl.training.checkpoint_freq\": 2,\n",
        "                        },\n",
        "                        #metric_definitions=metric_definitions, # This will bring all the logs out into the notebook.\n",
        "                    )\n",
        "\n",
        "estimator.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}